#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•¸æ“šé·ç§»è…³æœ¬
ç”¨æ–¼å°‡ FinMind æ•¸æ“šé·ç§»åˆ° PostgreSQL æ•¸æ“šåº«
"""

import os
import sys
import yaml
import pandas as pd
from datetime import datetime, timedelta
from loguru import logger

# æ·»åŠ  src ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.insert(0, os.path.join(os.path.dirname(__file__), "..", "..", "src"))

# ç›´æ¥å°å…¥æ¨¡çµ„ï¼Œä¸ä½¿ç”¨ src. å‰ç¶´
from modules.data_fetcher import FinMindFetcher


def load_config():
    """åŠ è¼‰é…ç½®æ–‡ä»¶"""
    config_path = os.path.join(os.path.dirname(__file__), "..", "..", "config.yaml")
    if not os.path.exists(config_path):
        logger.error(f"é…ç½®æ–‡ä»¶ {config_path} ä¸å­˜åœ¨")
        return None

    with open(config_path, "r", encoding="utf-8") as f:
        content = f.read()

    # è™•ç†ç’°å¢ƒè®Šé‡æ›¿æ›
    import re

    def replace_env_vars(match):
        env_var = match.group(1)
        default_value = match.group(2) if match.group(2) else ""
        result = os.getenv(env_var, default_value)
        logger.info(f"ç’°å¢ƒè®Šé‡æ›¿æ›: {env_var} -> {result}")
        return result

    # æ›¿æ› ${VAR:-default} æ ¼å¼çš„ç’°å¢ƒè®Šé‡
    # å…ˆæ‰“å°åŸå§‹å…§å®¹é€²è¡Œèª¿è©¦
    logger.info("åŸå§‹é…ç½®æ–‡ä»¶å…§å®¹:")
    logger.info(content)

    # ä½¿ç”¨æ›´ç°¡å–®çš„æ­£å‰‡è¡¨é”å¼
    pattern = r"\$\{([^:}]+):-([^}]*)\}"
    matches = re.findall(pattern, content)
    logger.info(f"æ‰¾åˆ°çš„ç’°å¢ƒè®Šé‡åŒ¹é…: {matches}")

    content = re.sub(pattern, replace_env_vars, content)

    # èª¿è©¦ï¼šæ‰“å°æ›¿æ›å¾Œçš„å…§å®¹
    logger.info("é…ç½®æ–‡ä»¶å…§å®¹ï¼ˆæ›¿æ›ç’°å¢ƒè®Šé‡å¾Œï¼‰:")
    logger.info(content)

    config = yaml.safe_load(content)
    return config


def setup_logging():
    """è¨­ç½®æ—¥èªŒ"""
    # å‰µå»ºæ—¥èªŒç›®éŒ„
    os.makedirs("logs", exist_ok=True)

    # é…ç½®æ—¥èªŒ
    logger.add(
        "logs/data_migrate.log",
        rotation="1 day",
        retention="7 days",
        level="INFO",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level} | {message}",
    )


def migrate_single_stock(
    fetcher: FinMindFetcher, stock_id: str, target_date: str = None
):
    """
    é·ç§»å–®æ”¯è‚¡ç¥¨çš„æ•¸æ“šï¼Œå¾æ—¥Kç·šè¨ˆç®—4å°æ™‚Kç·š

    Args:
        fetcher: FinMind æ•¸æ“šç²å–å™¨
        stock_id: è‚¡ç¥¨ä»£ç¢¼
        target_date: ç›®æ¨™æ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœç‚º None å‰‡ä½¿ç”¨ä»Šå¤©

    Returns:
        bool: é·ç§»æ˜¯å¦æˆåŠŸ
    """
    if target_date is None:
        target_date = datetime.now().strftime("%Y-%m-%d")

    logger.info(f"é–‹å§‹é·ç§»è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šï¼Œæ—¥æœŸ: {target_date}")

    try:
        # ç²å–è‚¡ç¥¨æ—¥Kç·šæ•¸æ“š
        df_daily = fetcher.get_stock_data(stock_id, target_date, target_date)

        if df_daily is None or df_daily.empty:
            logger.warning(f"è‚¡ç¥¨ {stock_id} åœ¨ {target_date} æ²’æœ‰æ—¥Kç·šæ•¸æ“š")
            return False

        logger.info(f"æˆåŠŸç²å–è‚¡ç¥¨ {stock_id} çš„ {len(df_daily)} ç­†æ—¥Kç·šæ•¸æ“š")

        # é¡¯ç¤ºæ—¥Kç·šæ•¸æ“šè©³æƒ…
        logger.info(f"æ—¥Kç·šæ•¸æ“šè©³æƒ…:")
        for _, row in df_daily.iterrows():
            logger.info(
                f"  æ—¥æœŸ: {row['date'].strftime('%Y-%m-%d')}, "
                f"é–‹ç›¤: {row['open']:.2f}, "
                f"æœ€é«˜: {row['high']:.2f}, "
                f"æœ€ä½: {row['low']:.2f}, "
                f"æ”¶ç›¤: {row['close']:.2f}, "
                f"æˆäº¤é‡: {row['volume']:,}"
            )

        # è½‰æ›æ—¥Kç·šç‚º4å°æ™‚Kç·šæ ¼å¼
        df_kline = convert_daily_to_4h_kline(df_daily, target_date)

        if df_kline is None or df_kline.empty:
            logger.error(f"ç„¡æ³•è½‰æ›è‚¡ç¥¨ {stock_id} çš„æ—¥Kç·šæ•¸æ“š")
            return False

        logger.info(f"æˆåŠŸè½‰æ› {len(df_kline)} ç­†Kç·šæ•¸æ“š")

        # é¡¯ç¤ºKç·šæ•¸æ“šè©³æƒ…
        logger.info(f"Kç·šæ•¸æ“šè©³æƒ…:")
        for _, row in df_kline.iterrows():
            logger.info(
                f"  æ™‚é–“: {row['date'].strftime('%Y-%m-%d %H:%M')}, "
                f"é–‹ç›¤: {row['open']:.2f}, "
                f"æœ€é«˜: {row['high']:.2f}, "
                f"æœ€ä½: {row['low']:.2f}, "
                f"æ”¶ç›¤: {row['close']:.2f}, "
                f"æˆäº¤é‡: {row['volume']:,}"
            )

        # é€£æ¥åˆ°æ•¸æ“šåº«
        if not fetcher.connect_database():
            logger.error("ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šåº«")
            return False

        # å­˜å„²Kç·šæ•¸æ“š
        success = fetcher.store_stock_data(stock_id, df_kline)

        if success:
            logger.info(f"âœ… è‚¡ç¥¨ {stock_id} Kç·šæ•¸æ“šé·ç§»æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ è‚¡ç¥¨ {stock_id} Kç·šæ•¸æ“šé·ç§»å¤±æ•—")
            return False

    except Exception as e:
        logger.error(f"é·ç§»è‚¡ç¥¨ {stock_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False
    finally:
        fetcher.close_database()


def migrate_single_stock_range(
    fetcher: FinMindFetcher, stock_id: str, start_date: str, end_date: str
):
    """
    é·ç§»å–®æ”¯è‚¡ç¥¨åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§çš„æ•¸æ“š

    Args:
        fetcher: FinMind æ•¸æ“šç²å–å™¨
        stock_id: è‚¡ç¥¨ä»£ç¢¼
        start_date: é–‹å§‹æ—¥æœŸ (YYYY-MM-DD)
        end_date: çµæŸæ—¥æœŸ (YYYY-MM-DD)

    Returns:
        bool: é·ç§»æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"é–‹å§‹é·ç§»è‚¡ç¥¨ {stock_id} çš„æ•¸æ“šï¼Œæ—¥æœŸç¯„åœ: {start_date} åˆ° {end_date}")

    try:
        # ç²å–è‚¡ç¥¨æ—¥Kç·šæ•¸æ“š
        df_daily = fetcher.get_stock_data(stock_id, start_date, end_date)

        if df_daily is None or df_daily.empty:
            logger.warning(f"è‚¡ç¥¨ {stock_id} åœ¨æŒ‡å®šæ—¥æœŸç¯„åœå…§æ²’æœ‰æ—¥Kç·šæ•¸æ“š")
            return False

        logger.info(f"æˆåŠŸç²å–è‚¡ç¥¨ {stock_id} çš„ {len(df_daily)} ç­†æ—¥Kç·šæ•¸æ“š")

        # é¡¯ç¤ºæ•¸æ“šçµ±è¨ˆ
        logger.info(f"æ•¸æ“šçµ±è¨ˆ:")
        logger.info(f"  ç¸½ç­†æ•¸: {len(df_daily)}")
        logger.info(f"  æ—¥æœŸç¯„åœ: {df_daily['date'].min()} åˆ° {df_daily['date'].max()}")
        logger.info(
            f"  åƒ¹æ ¼ç¯„åœ: {df_daily['low'].min():.2f} - {df_daily['high'].max():.2f}"
        )
        logger.info(f"  ç¸½æˆäº¤é‡: {df_daily['volume'].sum():,}")

        # è½‰æ›æ—¥Kç·šç‚º4å°æ™‚Kç·šæ ¼å¼
        df_kline = convert_daily_to_4h_kline_range(df_daily)

        if df_kline is None or df_kline.empty:
            logger.error(f"ç„¡æ³•è½‰æ›è‚¡ç¥¨ {stock_id} çš„æ—¥Kç·šæ•¸æ“š")
            return False

        logger.info(f"æˆåŠŸè½‰æ› {len(df_kline)} ç­†Kç·šæ•¸æ“š")

        # é€£æ¥åˆ°æ•¸æ“šåº«
        if not fetcher.connect_database():
            logger.error("ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šåº«")
            return False

        # å­˜å„²Kç·šæ•¸æ“š
        success = fetcher.store_stock_data(stock_id, df_kline)

        if success:
            logger.info(f"âœ… è‚¡ç¥¨ {stock_id} Kç·šæ•¸æ“šé·ç§»æˆåŠŸ")
            return True
        else:
            logger.error(f"âŒ è‚¡ç¥¨ {stock_id} Kç·šæ•¸æ“šé·ç§»å¤±æ•—")
            return False

    except Exception as e:
        logger.error(f"é·ç§»è‚¡ç¥¨ {stock_id} æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False
    finally:
        fetcher.close_database()


def convert_daily_to_4h_kline(df_daily: pd.DataFrame, target_date: str) -> pd.DataFrame:
    """
    å°‡æ—¥Kç·šè½‰æ›ç‚º4å°æ™‚Kç·šæ ¼å¼

    Args:
        df_daily: æ—¥Kç·šæ•¸æ“š
        target_date: ç›®æ¨™æ—¥æœŸ

    Returns:
        4å°æ™‚Kç·šæ ¼å¼çš„DataFrame
    """
    try:
        # å°å…¥4å°æ™‚Kç·šè¨ˆç®—å™¨
        from modules.kline.four_hour_calculator import FourHourKlineCalculator

        # åˆå§‹åŒ–è¨ˆç®—å™¨
        calculator = FourHourKlineCalculator()

        # ä½¿ç”¨é€²éšç®—æ³•è¨ˆç®—4å°æ™‚Kç·š
        df_kline = calculator.calculate_advanced_4h_kline(df_daily)

        logger.info(
            f"æˆåŠŸå°‡æ—¥Kç·šè½‰æ›ç‚º4å°æ™‚Kç·š: {len(df_daily)} å€‹äº¤æ˜“æ—¥ -> {len(df_kline)} æ ¹4å°æ™‚Kç·š"
        )
        return df_kline

    except Exception as e:
        logger.error(f"è½‰æ›æ—¥Kç·šç‚º4å°æ™‚Kç·šæ ¼å¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()


def convert_daily_to_4h_kline_range(df_daily: pd.DataFrame) -> pd.DataFrame:
    """
    å°‡å¤šæ—¥Kç·šè½‰æ›ç‚º4å°æ™‚Kç·šæ ¼å¼

    Args:
        df_daily: å¤šæ—¥æ—¥Kç·šæ•¸æ“š

    Returns:
        4å°æ™‚Kç·šæ ¼å¼çš„DataFrame
    """
    try:
        # å°å…¥4å°æ™‚Kç·šè¨ˆç®—å™¨
        from modules.kline.four_hour_calculator import FourHourKlineCalculator

        # åˆå§‹åŒ–è¨ˆç®—å™¨
        calculator = FourHourKlineCalculator()

        # ä½¿ç”¨é€²éšç®—æ³•è¨ˆç®—4å°æ™‚Kç·š
        df_kline = calculator.calculate_advanced_4h_kline(df_daily)

        logger.info(
            f"æˆåŠŸå°‡å¤šæ—¥æ—¥Kç·šè½‰æ›ç‚º4å°æ™‚Kç·š: {len(df_daily)} å€‹äº¤æ˜“æ—¥ -> {len(df_kline)} æ ¹4å°æ™‚Kç·š"
        )
        return df_kline

    except Exception as e:
        logger.error(f"è½‰æ›å¤šæ—¥æ—¥Kç·šç‚º4å°æ™‚Kç·šæ ¼å¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return pd.DataFrame()


def get_latest_data_date(fetcher: FinMindFetcher, stock_id: str) -> str:
    """
    ç²å–æ•¸æ“šåº«ä¸­è‚¡ç¥¨çš„æœ€æ–°æ•¸æ“šæ—¥æœŸ

    Args:
        fetcher: FinMind æ•¸æ“šç²å–å™¨
        stock_id: è‚¡ç¥¨ä»£ç¢¼

    Returns:
        str: æœ€æ–°æ•¸æ“šæ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœæ²’æœ‰æ•¸æ“šå‰‡è¿”å› None
    """
    try:
        if not fetcher.connect_database():
            logger.error("ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šåº«")
            return None

        cursor = fetcher.db_conn.cursor()

        # æŸ¥è©¢æœ€æ–°åƒ¹æ ¼æ•¸æ“šæ—¥æœŸ
        cursor.execute(
            """
            SELECT MAX(timestamp) 
            FROM price_data 
            WHERE symbol = %s
            """,
            (stock_id,),
        )
        result = cursor.fetchone()

        cursor.close()

        if result and result[0]:
            latest_date = result[0].strftime("%Y-%m-%d")
            logger.info(f"è‚¡ç¥¨ {stock_id} æœ€æ–°æ•¸æ“šæ—¥æœŸ: {latest_date}")
            return latest_date
        else:
            logger.info(f"è‚¡ç¥¨ {stock_id} åœ¨æ•¸æ“šåº«ä¸­æ²’æœ‰æ•¸æ“š")
            return None

    except Exception as e:
        logger.error(f"æŸ¥è©¢è‚¡ç¥¨ {stock_id} æœ€æ–°æ•¸æ“šæ—¥æœŸæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None
    finally:
        fetcher.close_database()


def verify_data_in_db(fetcher: FinMindFetcher, stock_id: str):
    """
    é©—è­‰æ•¸æ“šåº«ä¸­çš„æ•¸æ“š

    Args:
        fetcher: FinMind æ•¸æ“šç²å–å™¨
        stock_id: è‚¡ç¥¨ä»£ç¢¼

    Returns:
        bool: é©—è­‰æ˜¯å¦æˆåŠŸ
    """
    logger.info(f"é©—è­‰è‚¡ç¥¨ {stock_id} åœ¨æ•¸æ“šåº«ä¸­çš„æ•¸æ“š")

    try:
        if not fetcher.connect_database():
            logger.error("ç„¡æ³•é€£æ¥åˆ°æ•¸æ“šåº«")
            return False

        cursor = fetcher.db_conn.cursor()

        # æŸ¥è©¢è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        cursor.execute("SELECT * FROM stocks WHERE symbol = %s", (stock_id,))
        stock_info = cursor.fetchone()

        if stock_info:
            logger.info(f"âœ… è‚¡ç¥¨ {stock_id} åŸºæœ¬ä¿¡æ¯å·²å­˜åœ¨æ–¼æ•¸æ“šåº«")
            logger.info(f"  è‚¡ç¥¨ä»£ç¢¼: {stock_info[0]}, åç¨±: {stock_info[1]}")
        else:
            logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_id} åŸºæœ¬ä¿¡æ¯ä¸å­˜åœ¨æ–¼æ•¸æ“šåº«")

        # æŸ¥è©¢åƒ¹æ ¼æ•¸æ“š
        cursor.execute(
            """
            SELECT timestamp, open_price, high, low, close, volume 
            FROM price_data 
            WHERE symbol = %s
            ORDER BY timestamp DESC
            LIMIT 10
            """,
            (stock_id,),
        )
        price_data = cursor.fetchall()

        if price_data:
            logger.info(f"âœ… æ‰¾åˆ° {len(price_data)} ç­†åƒ¹æ ¼æ•¸æ“š")
            logger.info("æœ€è¿‘10ç­†æ•¸æ“š:")
            for row in price_data:
                logger.info(
                    f"  {row[0]} | O:{row[1]:.2f} H:{row[2]:.2f} "
                    f"L:{row[3]:.2f} C:{row[4]:.2f} V:{row[5]:,}"
                )
        else:
            logger.warning(f"âš ï¸ è‚¡ç¥¨ {stock_id} æ²’æœ‰åƒ¹æ ¼æ•¸æ“š")

        cursor.close()
        return True

    except Exception as e:
        logger.error(f"é©—è­‰æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False
    finally:
        fetcher.close_database()


def main():
    """ä¸»å‡½æ•¸"""
    print("=== FinMind æ•¸æ“šé·ç§»å·¥å…· ===")

    # è¨­ç½®æ—¥èªŒ
    setup_logging()

    # åŠ è¼‰é…ç½®
    config = load_config()
    if not config:
        print("âŒ ç„¡æ³•åŠ è¼‰é…ç½®æ–‡ä»¶")
        return

    # æª¢æŸ¥ FinMind API Token
    finmind_token = config.get("finmind", {}).get("token", "")
    if not finmind_token or finmind_token == "YOUR_FINMIND_TOKEN":
        print("âŒ FinMind API Token æœªè¨­ç½®")
        print("è«‹åœ¨ config.yaml ä¸­è¨­ç½®æ­£ç¢ºçš„ api_token")
        return

    print("âœ… FinMind API Token å·²è¨­ç½®")

    try:
        # å‰µå»ºæ•¸æ“šç²å–å™¨
        fetcher = FinMindFetcher(config)
        print("âœ… FinMind æ•¸æ“šç²å–å™¨å‰µå»ºæˆåŠŸ")

        # å¥åº·æª¢æŸ¥
        print("\n--- ç³»çµ±å¥åº·æª¢æŸ¥ ---")
        health_status = fetcher.health_check()
        print(f"API ç‹€æ…‹: {health_status['api_status']}")
        print(f"æ•¸æ“šåº«ç‹€æ…‹: {health_status['database_status']}")

        if health_status["api_status"] != "healthy":
            print("âŒ FinMind API é€£æ¥å¤±æ•—")
            return

        if health_status["database_status"] != "healthy":
            print("âŒ æ•¸æ“šåº«é€£æ¥å¤±æ•—")
            print("è«‹ç¢ºä¿ PostgreSQL æ•¸æ“šåº«æ­£åœ¨é‹è¡Œ")
            print("å¯ä»¥ä½¿ç”¨ ./start_db.sh å•Ÿå‹•æ•¸æ“šåº«æœå‹™")
            return

        print("âœ… ç³»çµ±å¥åº·æª¢æŸ¥é€šé")

        # é–‹å§‹æ•¸æ“šé·ç§»
        print("\n--- é–‹å§‹æ•¸æ“šé·ç§» ---")

        # å¾é…ç½®ä¸­ç²å–è‚¡ç¥¨æ± 
        stock_pool = config.get("trading", {}).get("stock_pool", [])
        if not stock_pool:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²’æœ‰æ‰¾åˆ°è‚¡ç¥¨æ±  (trading.stock_pool)")
            return

        print(f"è‚¡ç¥¨æ± : {stock_pool}")
        print(f"å…± {len(stock_pool)} æ”¯è‚¡ç¥¨éœ€è¦è™•ç†")

        # ç²å–ä»Šå¤©çš„æ—¥æœŸ
        today = datetime.now().strftime("%Y-%m-%d")
        print(f"ç›®æ¨™æ—¥æœŸ: {today}")

        # çµ±è¨ˆè®Šé‡
        success_count = 0
        total_count = len(stock_pool)

        # éæ­·è‚¡ç¥¨æ± é€²è¡Œé·ç§»
        for i, stock_id in enumerate(stock_pool, 1):
            print(f"\n--- è™•ç†è‚¡ç¥¨ {stock_id} ({i}/{total_count}) ---")

            try:
                # æª¢æŸ¥æ•¸æ“šåº«ä¸­æ˜¯å¦å·²æœ‰æ•¸æ“š
                latest_date = get_latest_data_date(fetcher, stock_id)

                if latest_date:
                    # æœ‰æ•¸æ“šï¼Œå¾æœ€å¾Œä¸€ç­†æ•¸æ“šçš„æ¬¡æ—¥é–‹å§‹é·ç§»
                    start_date = (
                        datetime.strptime(latest_date, "%Y-%m-%d") + timedelta(days=1)
                    ).strftime("%Y-%m-%d")
                    print(
                        f"è‚¡ç¥¨ {stock_id} å·²æœ‰æ•¸æ“šåˆ° {latest_date}ï¼Œå¾ {start_date} é–‹å§‹é·ç§»"
                    )

                    # æª¢æŸ¥æ˜¯å¦éœ€è¦é·ç§»ï¼ˆå¦‚æœæœ€æ–°æ—¥æœŸå·²ç¶“æ˜¯ä»Šå¤©æˆ–æ˜¨å¤©ï¼Œå¯èƒ½ä¸éœ€è¦é·ç§»ï¼‰
                    if start_date > today:
                        print(f"âœ… è‚¡ç¥¨ {stock_id} æ•¸æ“šå·²æ˜¯æœ€æ–°ï¼Œè·³éé·ç§»")
                        success_count += 1
                        continue

                    # å¦‚æœé–‹å§‹æ—¥æœŸå¤ªæ—©ï¼ˆè¶…é30å¤©å‰ï¼‰ï¼Œé™åˆ¶é·ç§»ç¯„åœä»¥é¿å…éå¤§çš„æ•¸æ“šé‡
                    start_datetime = datetime.strptime(start_date, "%Y-%m-%d")
                    today_datetime = datetime.strptime(today, "%Y-%m-%d")
                    days_diff = (today_datetime - start_datetime).days

                    if days_diff > 30:
                        # é™åˆ¶ç‚ºæœ€è¿‘30å¤©
                        start_date = (today_datetime - timedelta(days=30)).strftime(
                            "%Y-%m-%d"
                        )
                        print(
                            f"âš ï¸ è‚¡ç¥¨ {stock_id} éœ€è¦é·ç§»çš„æ•¸æ“šéå¤šï¼ˆ{days_diff}å¤©ï¼‰ï¼Œé™åˆ¶ç‚ºæœ€è¿‘30å¤©"
                        )
                else:
                    # æ²’æœ‰æ•¸æ“šï¼Œå¾2022å¹´é–‹å§‹é·ç§»
                    start_date = "2022-01-01"
                    print(f"è‚¡ç¥¨ {stock_id} æ²’æœ‰æ­·å²æ•¸æ“šï¼Œå¾ {start_date} é–‹å§‹é·ç§»")

                # åŸ·è¡Œé·ç§»
                success = migrate_single_stock_range(
                    fetcher, stock_id, start_date, today
                )

                if success:
                    print(f"âœ… è‚¡ç¥¨ {stock_id} æ•¸æ“šé·ç§»æˆåŠŸ")
                    success_count += 1

                    # é©—è­‰æ•¸æ“š
                    print(f"é©—è­‰è‚¡ç¥¨ {stock_id} çš„æ•¸æ“š...")
                    verify_success = verify_data_in_db(fetcher, stock_id)

                    if verify_success:
                        print(f"âœ… è‚¡ç¥¨ {stock_id} æ•¸æ“šé©—è­‰å®Œæˆ")
                    else:
                        print(f"âŒ è‚¡ç¥¨ {stock_id} æ•¸æ“šé©—è­‰å¤±æ•—")
                else:
                    print(f"âŒ è‚¡ç¥¨ {stock_id} æ•¸æ“šé·ç§»å¤±æ•—")

            except Exception as e:
                logger.error(f"è™•ç†è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                print(f"âŒ è™•ç†è‚¡ç¥¨ {stock_id} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

        # é¡¯ç¤ºæœ€çµ‚çµæœ
        print(f"\n--- æ•¸æ“šé·ç§»å®Œæˆ ---")
        print(f"æˆåŠŸè™•ç†: {success_count}/{total_count} æ”¯è‚¡ç¥¨")

        if success_count == total_count:
            print("ğŸ‰ æ‰€æœ‰è‚¡ç¥¨æ•¸æ“šé·ç§»æˆåŠŸï¼")
        else:
            print(f"âš ï¸ æœ‰ {total_count - success_count} æ”¯è‚¡ç¥¨é·ç§»å¤±æ•—")

    except Exception as e:
        logger.error(f"æ•¸æ“šé·ç§»éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
        print(f"âŒ æ•¸æ“šé·ç§»å¤±æ•—: {e}")

    print("\n=== æ•¸æ“šé·ç§»å®Œæˆ ===")


if __name__ == "__main__":
    main()
